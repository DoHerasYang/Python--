{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e3010b9",
   "metadata": {},
   "source": [
    "# 数据分析基础篇 - 数据预处理\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69b9f17",
   "metadata": {},
   "source": [
    "## 目录 - 数据预处理\n",
    "\n",
    "* [0. 数据预处理简介](#0.数据预处理)\n",
    "* [1. 数据清洗](#1.数据清洗)\n",
    " * [1.1 缺失值处理](#1.1-缺失值处理)\n",
    "   * [1.1.1 拉格朗日插值法](#1.1.1-拉格朗日插值法)\n",
    "   * [1.1.2 牛顿插值法](#1.1.2-牛顿插值法)\n",
    "   * [1.1.3 分段插值法 - 线性](#1.1.3-分段插值法---线性)\n",
    " * [1.2 异常值处理](#1.2-异常值处理)\n",
    "* [2.数据集成](#2.-数据集成)\n",
    " * [2.1 实体识别](#2.1-实体识别)\n",
    " * [2.2 冗余属性识别](#2.2-冗余属性识别)\n",
    " * [2.3 数据变换](#2.3-数据变换)\n",
    " * [2.4 简单函数变换](#2.4-简单函数变换)\n",
    " * [2.5 规范化(归一化)](#2.5-规范化(归一化))\n",
    "   * [2.5.1 最小-最大标准化](#2.5.1-最小-最大标准化)\n",
    "   * [2.5.2 零-均值标准化](#2.5.2-零-均值标准化)\n",
    "   * [2.5.3 小数定标标准化](#2.5.3-小数定标标准化)\n",
    "* [3.数据规约](#3.-数据归约)\n",
    " * [3.1 属性规约](#3.1-属性归约)\n",
    " * [3.2 数值规约](#3.2-数值归约)\n",
    "   * [3.2.1 非参数规约](#3.2.1-无参数据规约) \n",
    "   * [3.2.2 参数规约](#3.2.2-有参数据规约) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f889cdb7",
   "metadata": {},
   "source": [
    "## 0.数据预处理\n",
    "\n",
    "在之前的章节中（数据探索），我们知道大量的数据集可能存在着大量不完整（有缺失值）、不一致、有异常的数据，这些数据会影响到数据挖掘、建模的相关执行效率，甚至可能会导致挖掘结果的偏差，所以进行相关的数据预处理工作就非常重要。\n",
    "\n",
    "数据预处理的目的：\n",
    "\n",
    "+ 1. 提高数据的质量，使用相关数学方法处理缺失值、异常数据；\n",
    "+ 2. 让数据具有统一的格式并更好地适应特定的挖掘技术或者工具；\n",
    "\n",
    "数据预处理的技术（流程）：\n",
    "\n",
    "+ 1. 数据清洗： 填补缺失的值，光滑噪音数据、识别和删除离群点，解决数据的不一致性；\n",
    "+ 2. 数据集成： 使用多个源数据；\n",
    "+ 3. 数据归约： 使用较小的、替代的数据代替元数据，得到的信息的损失最小化；\n",
    "+ 4. 数据变换： 将数据进行相关的操作，标换成需要的挖掘形式；\n",
    "\n",
    "![1](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/roPWrjQ5nUG9X3FRJIibNB3zUMIRYKibEyPvotnEQUw28KXR0icr7s5lNOQoYdT3LJ2BicKdq5xEMn9txBc6jbzMwA/640?wx_fmt=png)\n",
    "\n",
    "数据预处理工作非常重要，数据的质量将会影响到最终的建模质量；\n",
    "\n",
    "参考链接：\n",
    "\n",
    "+ [为什么我们需要数据预处理？](https://blog.csdn.net/csdnnews/article/details/88265321)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab828309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_policy</th>\n",
       "      <th>purpose</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>log_annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>fico</th>\n",
       "      <th>days_with_cr_line</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>not_fully_paid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>829.10</td>\n",
       "      <td>11.350407</td>\n",
       "      <td>19.48</td>\n",
       "      <td>737</td>\n",
       "      <td>5639.958333</td>\n",
       "      <td>28854</td>\n",
       "      <td>52.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>228.22</td>\n",
       "      <td>11.082143</td>\n",
       "      <td>14.29</td>\n",
       "      <td>707</td>\n",
       "      <td>2760.000000</td>\n",
       "      <td>33623</td>\n",
       "      <td>76.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>0.1357</td>\n",
       "      <td>366.86</td>\n",
       "      <td>10.373491</td>\n",
       "      <td>11.63</td>\n",
       "      <td>682</td>\n",
       "      <td>4710.000000</td>\n",
       "      <td>3511</td>\n",
       "      <td>25.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>162.34</td>\n",
       "      <td>11.350407</td>\n",
       "      <td>8.10</td>\n",
       "      <td>712</td>\n",
       "      <td>2699.958333</td>\n",
       "      <td>33667</td>\n",
       "      <td>73.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>0.1426</td>\n",
       "      <td>102.92</td>\n",
       "      <td>11.299732</td>\n",
       "      <td>14.97</td>\n",
       "      <td>667</td>\n",
       "      <td>4066.000000</td>\n",
       "      <td>4740</td>\n",
       "      <td>39.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9573</th>\n",
       "      <td>0</td>\n",
       "      <td>all_other</td>\n",
       "      <td>0.1461</td>\n",
       "      <td>344.76</td>\n",
       "      <td>12.180755</td>\n",
       "      <td>10.39</td>\n",
       "      <td>672</td>\n",
       "      <td>10474.000000</td>\n",
       "      <td>215372</td>\n",
       "      <td>82.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9574</th>\n",
       "      <td>0</td>\n",
       "      <td>all_other</td>\n",
       "      <td>0.1253</td>\n",
       "      <td>257.70</td>\n",
       "      <td>11.141862</td>\n",
       "      <td>0.21</td>\n",
       "      <td>722</td>\n",
       "      <td>4380.000000</td>\n",
       "      <td>184</td>\n",
       "      <td>1.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9575</th>\n",
       "      <td>0</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>97.81</td>\n",
       "      <td>10.596635</td>\n",
       "      <td>13.09</td>\n",
       "      <td>687</td>\n",
       "      <td>3450.041667</td>\n",
       "      <td>10036</td>\n",
       "      <td>82.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9576</th>\n",
       "      <td>0</td>\n",
       "      <td>home_improvement</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>351.58</td>\n",
       "      <td>10.819778</td>\n",
       "      <td>19.18</td>\n",
       "      <td>692</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9577</th>\n",
       "      <td>0</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>0.1392</td>\n",
       "      <td>853.43</td>\n",
       "      <td>11.264464</td>\n",
       "      <td>16.28</td>\n",
       "      <td>732</td>\n",
       "      <td>4740.000000</td>\n",
       "      <td>37879</td>\n",
       "      <td>57.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9578 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      credit_policy             purpose  int_rate  installment  \\\n",
       "0                 1  debt_consolidation    0.1189       829.10   \n",
       "1                 1         credit_card    0.1071       228.22   \n",
       "2                 1  debt_consolidation    0.1357       366.86   \n",
       "3                 1  debt_consolidation    0.1008       162.34   \n",
       "4                 1         credit_card    0.1426       102.92   \n",
       "...             ...                 ...       ...          ...   \n",
       "9573              0           all_other    0.1461       344.76   \n",
       "9574              0           all_other    0.1253       257.70   \n",
       "9575              0  debt_consolidation    0.1071        97.81   \n",
       "9576              0    home_improvement    0.1600       351.58   \n",
       "9577              0  debt_consolidation    0.1392       853.43   \n",
       "\n",
       "      log_annual_inc    dti  fico  days_with_cr_line  revol_bal  revol_util  \\\n",
       "0          11.350407  19.48   737        5639.958333      28854        52.1   \n",
       "1          11.082143  14.29   707        2760.000000      33623        76.7   \n",
       "2          10.373491  11.63   682        4710.000000       3511        25.6   \n",
       "3          11.350407   8.10   712        2699.958333      33667        73.2   \n",
       "4          11.299732  14.97   667        4066.000000       4740        39.5   \n",
       "...              ...    ...   ...                ...        ...         ...   \n",
       "9573       12.180755  10.39   672       10474.000000     215372        82.1   \n",
       "9574       11.141862   0.21   722        4380.000000        184         1.1   \n",
       "9575       10.596635  13.09   687        3450.041667      10036        82.9   \n",
       "9576       10.819778  19.18   692        1800.000000          0         3.2   \n",
       "9577       11.264464  16.28   732        4740.000000      37879        57.0   \n",
       "\n",
       "      inq_last_6mths  delinq_2yrs  pub_rec  not_fully_paid  \n",
       "0                0.0          0.0      0.0               0  \n",
       "1                0.0          0.0      0.0               0  \n",
       "2                1.0          0.0      0.0               0  \n",
       "3                1.0          0.0      0.0               0  \n",
       "4                0.0          1.0      0.0               0  \n",
       "...              ...          ...      ...             ...  \n",
       "9573             2.0          0.0      0.0               1  \n",
       "9574             5.0          0.0      0.0               1  \n",
       "9575             8.0          0.0      0.0               1  \n",
       "9576             5.0          0.0      0.0               1  \n",
       "9577             6.0          0.0      0.0               1  \n",
       "\n",
       "[9578 rows x 14 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 先导入我们需要用到的相关数据集\n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import platform\n",
    "\n",
    "try:\n",
    "    data_file = pd.read_csv(\"../../issue_Documents/data/test_data/loans.csv\")\n",
    "except FileNotFoundError:\n",
    "    data_file = pd.read_csv(\"../issue_Documents/data/test_data/loans.csv\")\n",
    "\n",
    "data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b88c969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'是否符合信用承保标准': 'credit_policy',\n",
       " '贷款的目的': 'purpose',\n",
       " '贷款的利率': 'int_rate',\n",
       " '每月付款': 'installment',\n",
       " '年收入的自然对数': 'log_annual_inc',\n",
       " '借款人的债务收入比': 'dti',\n",
       " '借款人的 FICO 信用评分': 'fico',\n",
       " '借款人拥有信用额度的天数': 'days_with_cr_line',\n",
       " '借款人的循环余额': 'revol_bal',\n",
       " '借款人的循环线利用率': 'revol_util',\n",
       " '借款人最近6个月的债权人查询次数': 'inq_last_6mths',\n",
       " '借款人在过去 2 年内逾期 30 天以上的付款次数': 'delinq_2yrs',\n",
       " '借款人的贬义公共记录数量': 'pub_rec',\n",
       " '款是否未全额偿还': 'not_fully_paid'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在前边我们已经明确了相关列名的含义\n",
    "data_description = {'是否符合信用承保标准': 'credit_policy',\n",
    " '贷款的目的': 'purpose',\n",
    " '贷款的利率': 'int_rate',\n",
    " '每月付款': 'installment',\n",
    " '年收入的自然对数': 'log_annual_inc',\n",
    " '借款人的债务收入比': 'dti',\n",
    " '借款人的 FICO 信用评分': 'fico',\n",
    " '借款人拥有信用额度的天数': 'days_with_cr_line',\n",
    " '借款人的循环余额': 'revol_bal',\n",
    " '借款人的循环线利用率': 'revol_util',\n",
    " '借款人最近6个月的债权人查询次数': 'inq_last_6mths',\n",
    " '借款人在过去 2 年内逾期 30 天以上的付款次数': 'delinq_2yrs',\n",
    " '借款人的贬义公共记录数量': 'pub_rec',\n",
    " '款是否未全额偿还': 'not_fully_paid'}\n",
    "data_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5d616b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_policy</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>log_annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>fico</th>\n",
       "      <th>days_with_cr_line</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>not_fully_paid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>credit_policy</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.287878</td>\n",
       "      <td>0.073698</td>\n",
       "      <td>0.030228</td>\n",
       "      <td>-0.080286</td>\n",
       "      <td>0.352399</td>\n",
       "      <td>0.113409</td>\n",
       "      <td>-0.009222</td>\n",
       "      <td>-0.108413</td>\n",
       "      <td>-0.431072</td>\n",
       "      <td>-0.057907</td>\n",
       "      <td>-0.048810</td>\n",
       "      <td>-0.158119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_rate</th>\n",
       "      <td>-0.287878</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.242914</td>\n",
       "      <td>0.042297</td>\n",
       "      <td>0.216114</td>\n",
       "      <td>-0.744986</td>\n",
       "      <td>-0.133651</td>\n",
       "      <td>0.148719</td>\n",
       "      <td>0.472061</td>\n",
       "      <td>0.178337</td>\n",
       "      <td>0.173175</td>\n",
       "      <td>0.094207</td>\n",
       "      <td>0.152725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>installment</th>\n",
       "      <td>0.073698</td>\n",
       "      <td>0.242914</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.431826</td>\n",
       "      <td>0.062547</td>\n",
       "      <td>0.085257</td>\n",
       "      <td>0.202542</td>\n",
       "      <td>0.351844</td>\n",
       "      <td>0.094253</td>\n",
       "      <td>-0.003791</td>\n",
       "      <td>-0.007897</td>\n",
       "      <td>-0.027581</td>\n",
       "      <td>0.040404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_annual_inc</th>\n",
       "      <td>0.030228</td>\n",
       "      <td>0.042297</td>\n",
       "      <td>0.431826</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.059087</td>\n",
       "      <td>0.107281</td>\n",
       "      <td>0.399775</td>\n",
       "      <td>0.416840</td>\n",
       "      <td>0.054581</td>\n",
       "      <td>0.030083</td>\n",
       "      <td>0.030209</td>\n",
       "      <td>0.013187</td>\n",
       "      <td>-0.035382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dti</th>\n",
       "      <td>-0.080286</td>\n",
       "      <td>0.216114</td>\n",
       "      <td>0.062547</td>\n",
       "      <td>-0.059087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.214496</td>\n",
       "      <td>0.073319</td>\n",
       "      <td>0.375950</td>\n",
       "      <td>0.332962</td>\n",
       "      <td>0.030362</td>\n",
       "      <td>-0.018642</td>\n",
       "      <td>0.009284</td>\n",
       "      <td>0.035899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fico</th>\n",
       "      <td>0.352399</td>\n",
       "      <td>-0.744986</td>\n",
       "      <td>0.085257</td>\n",
       "      <td>0.107281</td>\n",
       "      <td>-0.214496</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.251221</td>\n",
       "      <td>-0.094562</td>\n",
       "      <td>-0.519832</td>\n",
       "      <td>-0.176155</td>\n",
       "      <td>-0.237364</td>\n",
       "      <td>-0.148011</td>\n",
       "      <td>-0.147920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days_with_cr_line</th>\n",
       "      <td>0.113409</td>\n",
       "      <td>-0.133651</td>\n",
       "      <td>0.202542</td>\n",
       "      <td>0.399775</td>\n",
       "      <td>0.073319</td>\n",
       "      <td>0.251221</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.325609</td>\n",
       "      <td>-0.003214</td>\n",
       "      <td>-0.042789</td>\n",
       "      <td>0.095395</td>\n",
       "      <td>0.101220</td>\n",
       "      <td>-0.024862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revol_bal</th>\n",
       "      <td>-0.009222</td>\n",
       "      <td>0.148719</td>\n",
       "      <td>0.351844</td>\n",
       "      <td>0.416840</td>\n",
       "      <td>0.375950</td>\n",
       "      <td>-0.094562</td>\n",
       "      <td>0.325609</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.516591</td>\n",
       "      <td>-0.018197</td>\n",
       "      <td>-0.053698</td>\n",
       "      <td>-0.025586</td>\n",
       "      <td>0.020440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revol_util</th>\n",
       "      <td>-0.108413</td>\n",
       "      <td>0.472061</td>\n",
       "      <td>0.094253</td>\n",
       "      <td>0.054581</td>\n",
       "      <td>0.332962</td>\n",
       "      <td>-0.519832</td>\n",
       "      <td>-0.003214</td>\n",
       "      <td>0.516591</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.013029</td>\n",
       "      <td>-0.032031</td>\n",
       "      <td>0.072230</td>\n",
       "      <td>0.081395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <td>-0.431072</td>\n",
       "      <td>0.178337</td>\n",
       "      <td>-0.003791</td>\n",
       "      <td>0.030083</td>\n",
       "      <td>0.030362</td>\n",
       "      <td>-0.176155</td>\n",
       "      <td>-0.042789</td>\n",
       "      <td>-0.018197</td>\n",
       "      <td>-0.013029</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020471</td>\n",
       "      <td>0.057275</td>\n",
       "      <td>0.132034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <td>-0.057907</td>\n",
       "      <td>0.173175</td>\n",
       "      <td>-0.007897</td>\n",
       "      <td>0.030209</td>\n",
       "      <td>-0.018642</td>\n",
       "      <td>-0.237364</td>\n",
       "      <td>0.095395</td>\n",
       "      <td>-0.053698</td>\n",
       "      <td>-0.032031</td>\n",
       "      <td>0.020471</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001731</td>\n",
       "      <td>0.015276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pub_rec</th>\n",
       "      <td>-0.048810</td>\n",
       "      <td>0.094207</td>\n",
       "      <td>-0.027581</td>\n",
       "      <td>0.013187</td>\n",
       "      <td>0.009284</td>\n",
       "      <td>-0.148011</td>\n",
       "      <td>0.101220</td>\n",
       "      <td>-0.025586</td>\n",
       "      <td>0.072230</td>\n",
       "      <td>0.057275</td>\n",
       "      <td>0.001731</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.059067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not_fully_paid</th>\n",
       "      <td>-0.158119</td>\n",
       "      <td>0.152725</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>-0.035382</td>\n",
       "      <td>0.035899</td>\n",
       "      <td>-0.147920</td>\n",
       "      <td>-0.024862</td>\n",
       "      <td>0.020440</td>\n",
       "      <td>0.081395</td>\n",
       "      <td>0.132034</td>\n",
       "      <td>0.015276</td>\n",
       "      <td>0.059067</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   credit_policy  int_rate  installment  log_annual_inc  \\\n",
       "credit_policy           1.000000 -0.287878     0.073698        0.030228   \n",
       "int_rate               -0.287878  1.000000     0.242914        0.042297   \n",
       "installment             0.073698  0.242914     1.000000        0.431826   \n",
       "log_annual_inc          0.030228  0.042297     0.431826        1.000000   \n",
       "dti                    -0.080286  0.216114     0.062547       -0.059087   \n",
       "fico                    0.352399 -0.744986     0.085257        0.107281   \n",
       "days_with_cr_line       0.113409 -0.133651     0.202542        0.399775   \n",
       "revol_bal              -0.009222  0.148719     0.351844        0.416840   \n",
       "revol_util             -0.108413  0.472061     0.094253        0.054581   \n",
       "inq_last_6mths         -0.431072  0.178337    -0.003791        0.030083   \n",
       "delinq_2yrs            -0.057907  0.173175    -0.007897        0.030209   \n",
       "pub_rec                -0.048810  0.094207    -0.027581        0.013187   \n",
       "not_fully_paid         -0.158119  0.152725     0.040404       -0.035382   \n",
       "\n",
       "                        dti      fico  days_with_cr_line  revol_bal  \\\n",
       "credit_policy     -0.080286  0.352399           0.113409  -0.009222   \n",
       "int_rate           0.216114 -0.744986          -0.133651   0.148719   \n",
       "installment        0.062547  0.085257           0.202542   0.351844   \n",
       "log_annual_inc    -0.059087  0.107281           0.399775   0.416840   \n",
       "dti                1.000000 -0.214496           0.073319   0.375950   \n",
       "fico              -0.214496  1.000000           0.251221  -0.094562   \n",
       "days_with_cr_line  0.073319  0.251221           1.000000   0.325609   \n",
       "revol_bal          0.375950 -0.094562           0.325609   1.000000   \n",
       "revol_util         0.332962 -0.519832          -0.003214   0.516591   \n",
       "inq_last_6mths     0.030362 -0.176155          -0.042789  -0.018197   \n",
       "delinq_2yrs       -0.018642 -0.237364           0.095395  -0.053698   \n",
       "pub_rec            0.009284 -0.148011           0.101220  -0.025586   \n",
       "not_fully_paid     0.035899 -0.147920          -0.024862   0.020440   \n",
       "\n",
       "                   revol_util  inq_last_6mths  delinq_2yrs   pub_rec  \\\n",
       "credit_policy       -0.108413       -0.431072    -0.057907 -0.048810   \n",
       "int_rate             0.472061        0.178337     0.173175  0.094207   \n",
       "installment          0.094253       -0.003791    -0.007897 -0.027581   \n",
       "log_annual_inc       0.054581        0.030083     0.030209  0.013187   \n",
       "dti                  0.332962        0.030362    -0.018642  0.009284   \n",
       "fico                -0.519832       -0.176155    -0.237364 -0.148011   \n",
       "days_with_cr_line   -0.003214       -0.042789     0.095395  0.101220   \n",
       "revol_bal            0.516591       -0.018197    -0.053698 -0.025586   \n",
       "revol_util           1.000000       -0.013029    -0.032031  0.072230   \n",
       "inq_last_6mths      -0.013029        1.000000     0.020471  0.057275   \n",
       "delinq_2yrs         -0.032031        0.020471     1.000000  0.001731   \n",
       "pub_rec              0.072230        0.057275     0.001731  1.000000   \n",
       "not_fully_paid       0.081395        0.132034     0.015276  0.059067   \n",
       "\n",
       "                   not_fully_paid  \n",
       "credit_policy           -0.158119  \n",
       "int_rate                 0.152725  \n",
       "installment              0.040404  \n",
       "log_annual_inc          -0.035382  \n",
       "dti                      0.035899  \n",
       "fico                    -0.147920  \n",
       "days_with_cr_line       -0.024862  \n",
       "revol_bal                0.020440  \n",
       "revol_util               0.081395  \n",
       "inq_last_6mths           0.132034  \n",
       "delinq_2yrs              0.015276  \n",
       "pub_rec                  0.059067  \n",
       "not_fully_paid           1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file.corr(method=\"spearman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eabbdf",
   "metadata": {},
   "source": [
    "> 可能目前对相关的库不是很熟悉，或者根本不了解，但是看永远是看不会的，带着问题去解决问题永远比去看要快很多；<br>\n",
    "> Ganbare!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669192bf",
   "metadata": {},
   "source": [
    "## 1.数据清洗\n",
    "\n",
    "数据清洗的主要目的就是处理原有数据集中影响建模的相关数据，其缺失值的主要分类有：\n",
    "\n",
    "+ 无关数据\n",
    "+ 重复数据\n",
    "+ 平滑的噪声数据\n",
    "+ 筛选与主题无关的数据\n",
    "+ 处理缺失值\n",
    "+ 异常值\n",
    "\n",
    "<br>\n",
    "\n",
    "### 1.1 缺失值处理\n",
    "\n",
    "缺失值指的是在数据集中出现没有数据的一行或者一列，常用的处理方法：\n",
    "\n",
    "+ 删除记录：将出现缺失值的一列或者一行删除掉；\n",
    "+ 数据插补：均值、中位数、众数、固定值、近邻值插补、回归模型得出的值、近似插值法进行插补；\n",
    "+ 不处理\n",
    "\n",
    "删除记录的方法存在的问题： 在数据集本来就很小的情况下，删除缺失值可能会造成相关数据资源的浪费，会丢失相应隐藏的相关信息，从而影响最终结果的客观性；\n",
    "\n",
    "在这里主要介绍： **拉格朗日插值法**、**牛顿插值法**、**分段插值法**、**样条插值法**\n",
    "\n",
    "<br>\n",
    "\n",
    "#### 1.1.1 拉格朗日插值法\n",
    "\n",
    "在线性代数中（数学基础），任意一个坐标点都可以找到一个线性相关公式：$y=a_0+a_1+a_2+a_3+\\cdots+a_{n-1}x^{n-1}$ 来表示某个点的线性特征；\n",
    "\n",
    "如果有 $n$ 个点，那么将这 $n$个坐标 $(x_1,y_1)(x_2,y_2)\\cdots(x_i,y_i)$带入多项式函数：\n",
    "\n",
    "\n",
    "<br>\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\left\\{\n",
    "    \\begin{array}{**lr**}\n",
    "    y_1 = a_0+a_1x_1+a_2x_1^2+\\cdots+a_{n-1}x_1^{n-1} & \\\\\n",
    "    y_2 = a_0+a_1x_1+a_2x_2^2+\\cdots+a_{n-1}x_2^{n-1} & \\\\\n",
    "    \\vdots \\\\\n",
    "    y_n = a_0+a_1x_1+a_2x_2^2+\\cdots+a_{n-1}x_2^{n-1} & \\\\\n",
    "    \\end{array}\n",
    "\\right.\n",
    "\\end{equation}\n",
    "$$\n",
    "<br>\n",
    "\n",
    "\n",
    "即在这个场景下：我们需要明白一点，就是所有数据集中的数值都可以通过上边的公式进行表示；\n",
    "\n",
    "现在问题就是：在 Pandas 中，缺失的值极个别地出现在某些行中，设缺失的值为：$y_i$，缺失的列为: $col_i$，需要参考没有缺失的其他行的其他列($\\lnot{a}$)：$x_1,x_2,\\cdots,x_{i-1}$ 以及 $y_i({a})$;\n",
    "\n",
    "\n",
    "我们假设存在这样的多项式 $f(x)$，满足下边的要求：\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "f(x) = y_1f_1(x_1) + y_2f_2(x_2) + y_3f_3(x_3) + \\cdots + y_{i}f(x_{i})\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "这个公式需要满足下边的条件，我们以 $i=3$ 来进行举例：\n",
    "\n",
    "$$\n",
    "f(x_1) = y_1f_1(x_1)\n",
    "f(x_2) = y_2f_2(x_2)\n",
    "f(x_3) = y_3f_3(x_3)\n",
    "$$\n",
    "<br>\n",
    "\n",
    "即在 $y_1f_1(x_1)=y_1$ 时，同时满足 $f_2(x_2)=0$ $f_3(x_3)=0$\n",
    "其他参数构建的插值基函数与这个特征类同；\n",
    "\n",
    "即我们需要构造这样的插值基函数，满足在 $x_{i}$ 条件下：\n",
    "\n",
    "$$\n",
    "f(x) = y_{j}f_{j}(x_j) = y_{j}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\sum_{i \\neq j}^i{f_j(x_j) = 0}\n",
    "$$\n",
    "\n",
    "在数学中我们都知道，$1\\cdot x = x$ 和 $0 \\cdot x = 0$，因此构造的公式也类似；\n",
    "\n",
    "在多值插项式中，可以构建如下的公式，满足：\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "f_j(x_j)\n",
    "\\left\\{\n",
    "    \\begin{array}{**lr**}\n",
    "    1 & i=j     \\\\\n",
    "    0 & i\\neq j   \\\\\n",
    "    \\end{array}\n",
    "\\right.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "以 $i\\in (1,2,3)$ 举例，定义插值基函数 $f_1(x)$：\n",
    "\n",
    "$$\n",
    "f_1(x) = y_1\\frac{(x-x_2)(x-x_3)}{(x_1-x_2)(x_1-x_3)}\n",
    "$$\n",
    "\n",
    "我们将上边的公式进行验证：\n",
    "\n",
    "当 $x_{i=1}$ 时：\n",
    "\n",
    "$$\n",
    "f_1(x_1) = y_1 \\frac{(x_1-x_2)(x_1-x_3)}{(x_1-x_2)(x_1-x_3)} = 1\n",
    "$$\n",
    "\n",
    "当 $x_{i=2}$ 时：\n",
    "\n",
    "$$\n",
    "f_1(x_2) = y_2 \\frac{(x_2-x_2)(x_2-x_3)}{(x_1-x_2)(x_1-x_3)} = 0\n",
    "$$\n",
    "\n",
    "当 $x_{i=3}$ 时，同上， $f_1(x_3) = 0$：\n",
    "\n",
    "\n",
    "即从上边的例子，可以推导出：\n",
    "\n",
    "$$\n",
    "y_i = y_1\\frac{(x_i-x_2)(x_i-x_3)}{(x_1-x_2)(x_1-x_3)} + y_2\\frac{(x_i-x1)(x_i-x_3)}{(x_2-x_1)(x_2-x_3)} + y_3\\frac{(x_i-x_1)(x_i-x_2)}{(x_3-x_1)(x_3-x_2)}\n",
    "$$\n",
    "\n",
    "可能会有点疑惑，上边的公式的适用的场景是：知道了三个点 $(x_1,y_1)$ $(x_2,{y_2})$ $(x_3,y_3)$，求在第四个点的坐标：$(x_4,y_4)$ 的 $y$ 值；\n",
    "\n",
    "得到通用公式：\n",
    "\n",
    "$$\n",
    "y = \\sum_{i=0}^n{y_i(\\prod_{j=0,j \\neq i}^n\\frac{x-x_j}{x_i-x_j})}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "请参考 `scipy.lagerange` 函数来生成对应的多项式：[scipy.interpolate.lagrange](https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.lagrange.html)\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "数据分析应用场景 - Pandas：\n",
    "\n",
    "+ 在 $col_1, col_2, \\cdots , col_n$ 中可能会存在空值行，设 $ col_n=x_n $；\n",
    "+ 1. 选取一列 `DataFrame`，记为 `Series (se)` ；\n",
    "+ 2. 取一个数：`k`，这个数代表取空值行前后行的行数，用来做拉格朗日的插值分析数字；\n",
    "+ 3. 我们构成这样的数据结构：$$ (x,y) \\\\ \\updownarrow \\\\ (x:代表行数{index},\\; y:代表选取的列在行{index}值{se[index]}) $$ <br>\n",
    "+ 4. 因此构建的拉格朗日的相关点的坐标数据是，以 $ i=5 为空行 $  $ k=3 $ 进行举例：\n",
    "    + $(2,se[2])\\;(3,se[3])\\;(4,se[4])\\;(6,se[6])\\;(7,se[7])\\;(8,se[8])$ : 其中数字$n$都是行号，$se[n]$是对应的选取列和行的值；\n",
    "    + $(5,y)$ 是我们需要求的目标数据值，即以上边的几个点数据构建的拉格朗日多项式来求出空值：$y$\n",
    "\n",
    "\n",
    "参考链接：\n",
    "\n",
    "+ [如何直观地理解拉格朗日插值法？](https://www.zhihu.com/question/58333118)\n",
    "+ [拉格朗日插值法(图文详解)](https://www.cnblogs.com/ECJTUACM-873284962/p/6833391.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c571eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "credit_policy         0\n",
       "purpose               0\n",
       "int_rate              0\n",
       "installment           0\n",
       "log_annual_inc        4\n",
       "dti                   0\n",
       "fico                  0\n",
       "days_with_cr_line    29\n",
       "revol_bal             0\n",
       "revol_util           62\n",
       "inq_last_6mths       29\n",
       "delinq_2yrs          29\n",
       "pub_rec              29\n",
       "not_fully_paid        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 现在我们来演示一下拉格朗日插值法在实际中的应用，因为这个方法比较繁琐不是很常用，但是是非常关键的一个概念；\n",
    "# 延伸概念：范德蒙矩阵 / 牛顿插值法\n",
    "# 先打印空值行\n",
    "data_file.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9e4c9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       11.350407\n",
       "1       11.082143\n",
       "2       10.373491\n",
       "3       11.350407\n",
       "4       11.299732\n",
       "          ...    \n",
       "9573    12.180755\n",
       "9574    11.141862\n",
       "9575    10.596635\n",
       "9576    10.819778\n",
       "9577    11.264464\n",
       "Name: log_annual_inc, Length: 9578, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 我们选取值比较接近的数据列进行比较 - log_annual_inc\n",
    "data_file[\"log_annual_inc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed1feb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7726   NaN\n",
       "7741   NaN\n",
       "7742   NaN\n",
       "7743   NaN\n",
       "Name: log_annual_inc, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 打印一下相关的数据特征\n",
    "# 在这里我们先复制一下新的对象到内存中，具体请参考： pandas.DataFrame.copy 函数\n",
    "data_file_copy = data_file.copy()\n",
    "log_se = data_file_copy[\"log_annual_inc\"]\n",
    "log_se[log_se.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c98a9ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.12236338"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 打印这个区间的最大值\n",
    "log_se[7700:7800].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e63b138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.29404964"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 打印区间\n",
    "log_se[7700:7800].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48ca23cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7726, 7741, 7742, 7743]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 打印缺失值的区间\n",
    "null_valueIndex = log_se[log_se.isnull()].index.to_list()\n",
    "null_valueIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3d662d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/doheras/opt/anaconda3/envs/auto_Demo/lib/python3.7/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7726    11.480101\n",
       "7741    11.022719\n",
       "7742    11.299090\n",
       "7743    11.226997\n",
       "Name: log_annual_inc, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.interpolate import lagrange\n",
    "\n",
    "data_file_copy = data_file.copy()\n",
    "log_se = data_file_copy[\"log_annual_inc\"]\n",
    "\n",
    "# 现在我们构建对应的函数 - pd_lagrange() 来撰写\n",
    "# 获取对应的空值 - list\n",
    "null_valueIndex = log_se[log_se.isnull()].index.to_list()\n",
    "\n",
    "# 构建新的函数 pd_lagrange\n",
    "def pd_lagrange(se: pd.Series, null_valueIndex: list, k=2):\n",
    "    # se: Pandas.Series 数据结构\n",
    "    # null_valueIndex: List 存放空值行数\n",
    "    # k: 选取前后行的数字\n",
    "    \n",
    "    # 遍历所有的空值行\n",
    "    for index in null_valueIndex:\n",
    "        # 选取上下K的数据\n",
    "        y_se = se[list(range(index-k,index)) + list(range(index+1, index+k+1))]\n",
    "        # 将空值的行去掉\n",
    "        y_se = y_se[y_se.notnull()]\n",
    "        # 将上边所有的值输入到拉格朗日多项式中，并且生成一个新的多项式；\n",
    "        # 并使用 pd.loc 函数来重新赋值空值行\n",
    "        se.loc[index] = scipy.interpolate.lagrange(list(y_se.index), list(y_se))(index)\n",
    "\n",
    "# 运行 pd_lagrange 函数来填补相关的缺陷值\n",
    "pd_lagrange(log_se, null_valueIndex, k=2)\n",
    "\n",
    "# 打印出原来空值的相关行\n",
    "log_se[null_valueIndex]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a6b406",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**练习**\n",
    "$\\textsf{TODO - 1.1:}$\n",
    "\n",
    "请使用 `log_annual_inc` 列数据进行下边的练习；\n",
    "\n",
    "+ 1. 在上边我们知道了如何使用拉格朗日插值法来处理缺失的值，在我们定义的拉格朗日插值模型时，定义了一个 $k$ 值来选取空值行周围的没有空值的近邻行，请尝试更改 $k$ 值并打印出相关的缺失值填充结果，并说出在不同`k`值时你的发现；\n",
    "+ 2. 在上边的函数： `pd_lagrange` 函数中确定了我们的构建代码，但是在这个代码中存在相关的问题，将下边这两个：\n",
    "    + 2.1 - 通过观察，我们发现$x$ 的值过大( $7700<x<7800$ )，而 $y$ 的取值范围( $8.29404964 \\leq y \\leq 13.12236338$ )，存在数据不平衡的问题，请尝试减小 $x$ 的值来重新构建函数；\n",
    "    + 2.2 - 通过观察我们发现，缺失值区间中有的缺失值是呈现连续的，比如(7741, 7742, 7743)，这样我们在取非缺失点时就会出现问题，请尝试使用其他方法来改变这个问题；\n",
    "    + 2.3 - 在更改之后，请思考 `k` 的取值对于在不同`x`取值时的大小特点，即是否可以更改`k`值来提升拉格朗日多项式插值法对于缺失值的预测情况；\n",
    "+ 参考思路：\n",
    "    + 对于 $x$ 的值过大，我们可以尝试减去一个值,构建一个标准的坐标式，再放入到 lagrange 函数中构建拉格朗日多项式；\n",
    "    + 连续的问题，我们可以使用： `pandas.DataFrmae.sample.reset_index` 函数来打乱数据；\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a118f84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "进行 k 值遍历:\n",
      "k 的取值是：1\n",
      "7726    11.425749\n",
      "7741    10.463103\n",
      "7742    10.463103\n",
      "7743    10.732602\n",
      "Name: log_annual_inc, dtype: float64\n",
      "\n",
      "\n",
      "k 的取值是：2\n",
      "7726    11.480101\n",
      "7741    11.022719\n",
      "7742    11.299090\n",
      "7743    11.226997\n",
      "Name: log_annual_inc, dtype: float64\n",
      "\n",
      "\n",
      "k 的取值是：3\n",
      "7726   -7824.000000\n",
      "7741      11.564598\n",
      "7742      11.843750\n",
      "7743   -3456.000000\n",
      "Name: log_annual_inc, dtype: float64\n",
      "\n",
      "\n",
      "k 的取值是：4\n",
      "7726    9.294578e+10\n",
      "7741    8.960000e+02\n",
      "7742    2.281701e+09\n",
      "7743   -1.614090e+19\n",
      "Name: log_annual_inc, dtype: float64\n",
      "\n",
      "\n",
      "k 的取值是：5\n",
      "7726    2.852749e+18\n",
      "7741    2.630667e+10\n",
      "7742   -2.786196e+23\n",
      "7743   -1.395158e+40\n",
      "Name: log_annual_inc, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 解决 1.1 的第一个问题，我们只需要在后边构建一个迭代器就OK了\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce9dfe53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "乱序之前的序号：\n",
      "[7726, 7741, 7742, 7743]\n",
      "\n",
      "\n",
      "乱序之后的序号：\n",
      "[562, 3275, 6619, 8744]\n"
     ]
    }
   ],
   "source": [
    "# 我们先尝试打乱一下 DataFrame， 使用 pandas.DataFrame.sample.reset_index\n",
    "# 考虑打乱相关的数据集\n",
    "data_file_copy = data_file.copy()\n",
    "data_file_copy = data_file_copy.sample(frac=1.0).reset_index(drop=True)\n",
    "# 再尝试打印一下相关的信息 - log_annual_inc\n",
    "log_se = data_file_copy[\"log_annual_inc\"]\n",
    "print(\"乱序之前的序号：\")\n",
    "print(list(data_file[data_file[\"log_annual_inc\"].isnull()][\"log_annual_inc\"].index))\n",
    "print(\"\\n\")\n",
    "print(\"乱序之后的序号：\")\n",
    "print(list(log_se[log_se.isnull()].index))\n",
    "# 通过上边的 null_valueIndex 进行比对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c9b8906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "乱序之前的序号：\n",
      "[7726, 7741, 7742, 7743]\n",
      "\n",
      "\n",
      "乱序之后的序号：\n",
      "[2175, 2715, 4135, 4877]\n"
     ]
    }
   ],
   "source": [
    "# 在 Panda 你可以指定 seed(random_state) 来保证每次的打乱的结果是相同的\n",
    "data_file_copy = data_file.copy()\n",
    "data_file_copy = data_file_copy.sample(frac=1.0, random_state = 23).reset_index(drop=True)\n",
    "# 再尝试打印一下相关的信息 - log_annual_inc\n",
    "log_se = data_file_copy[\"log_annual_inc\"]\n",
    "print(\"乱序之前的序号：\")\n",
    "print(list(data_file[data_file[\"log_annual_inc\"].isnull()][\"log_annual_inc\"].index))\n",
    "print(\"\\n\")\n",
    "print(\"乱序之后的序号：\")\n",
    "print(list(log_se[log_se.isnull()].index))\n",
    "# 在这里不管你运行多少次，乱序之后的序号都是相同的，因此可以有效地来进行数据结果的操控；\n",
    "# 可以在后边的练习 1.1 中使用这个特性，来验证你的想法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37518db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "进行 x 的相关规约化函数的结果（打乱原先的数据集并将X的值进行集中）: \n",
      "\n",
      "------\n",
      "对 x 进行相关规约集中之前的序号是：[200 3705 4585 7418]\n",
      "选取的行：200\n",
      "对 x 进行相关规约集中之后的序号是：[0 2]\n",
      "选取的行：3705\n",
      "对 x 进行相关规约集中之后的序号是：[0 2]\n",
      "选取的行：4585\n",
      "对 x 进行相关规约集中之后的序号是：[0 2]\n",
      "选取的行：7418\n",
      "对 x 进行相关规约集中之后的序号是：[0 2]\n",
      "k 的取值是：1\n",
      "200     10.487557\n",
      "3705    10.755812\n",
      "4585    10.612081\n",
      "7418    10.893988\n",
      "Name: log_annual_inc, dtype: float64\n",
      "------\n",
      "\n",
      "\n",
      "------\n",
      "对 x 进行相关规约集中之前的序号是：[1071 2188 2521 5884]\n",
      "选取的行：1071\n",
      "对 x 进行相关规约集中之后的序号是：[0 1 3 4]\n",
      "选取的行：2188\n",
      "对 x 进行相关规约集中之后的序号是：[0 1 3 4]\n",
      "选取的行：2521\n",
      "对 x 进行相关规约集中之后的序号是：[0 1 3 4]\n",
      "选取的行：5884\n",
      "对 x 进行相关规约集中之后的序号是：[0 1 3 4]\n",
      "k 的取值是：2\n",
      "1071    10.666122\n",
      "2188    10.411392\n",
      "2521    10.210633\n",
      "5884    11.157987\n",
      "Name: log_annual_inc, dtype: float64\n",
      "------\n",
      "\n",
      "\n",
      "------\n",
      "对 x 进行相关规约集中之前的序号是：[2411 4867 5321 8128]\n",
      "选取的行：2411\n",
      "对 x 进行相关规约集中之后的序号是：[0 1 2 4 5 6]\n",
      "选取的行：4867\n",
      "对 x 进行相关规约集中之后的序号是：[0 1 2 4 5 6]\n",
      "选取的行：5321\n",
      "对 x 进行相关规约集中之后的序号是：[0 1 2 4 5 6]\n",
      "选取的行：8128\n",
      "对 x 进行相关规约集中之后的序号是：[0 1 2 4 5 6]\n",
      "k 的取值是：3\n",
      "2411     9.751268\n",
      "4867    11.578815\n",
      "5321    11.629000\n",
      "8128    10.591625\n",
      "Name: log_annual_inc, dtype: float64\n",
      "------\n",
      "\n",
      "\n",
      "------\n",
      "对 x 进行相关规约集中之前的序号是：[3551 6253 6627 8851]\n",
      "选取的行：3551\n",
      "对 x 进行相关规约集中之后的序号是：[0 1 2 3 5 6 7 8]\n",
      "选取的行：6253\n",
      "对 x 进行相关规约集中之后的序号是：[0 1 2 3 5 6 7 8]\n",
      "选取的行：6627\n",
      "对 x 进行相关规约集中之后的序号是：[0 1 2 3 5 6 7 8]\n",
      "选取的行：8851\n",
      "对 x 进行相关规约集中之后的序号是：[0 1 2 3 5 6 7 8]\n",
      "k 的取值是：4\n",
      "3551    10.999996\n",
      "6253    10.464747\n",
      "6627    11.425323\n",
      "8851    11.435679\n",
      "Name: log_annual_inc, dtype: float64\n",
      "------\n",
      "\n",
      "\n",
      "------\n",
      "对 x 进行相关规约集中之前的序号是：[273 2119 3563 7719]\n",
      "选取的行：273\n",
      "对 x 进行相关规约集中之后的序号是：[0 1 2 3 4 6 7 8 9 10]\n",
      "选取的行：2119\n",
      "对 x 进行相关规约集中之后的序号是：[0 1 2 3 4 6 7 8 9 10]\n",
      "选取的行：3563\n",
      "对 x 进行相关规约集中之后的序号是：[0 1 2 3 4 6 7 8 9 10]\n",
      "选取的行：7719\n",
      "对 x 进行相关规约集中之后的序号是：[0 1 2 3 4 6 7 8 9 10]\n",
      "k 的取值是：5\n",
      "273     12.005330\n",
      "2119    11.467294\n",
      "3563     9.935789\n",
      "7719     9.841851\n",
      "Name: log_annual_inc, dtype: float64\n",
      "------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2.1 2.2 2.3 解决代码\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb94fe06",
   "metadata": {},
   "source": [
    "#### 1.1.2 牛顿插值法\n",
    "\n",
    "牛顿插值法简单来说，就是对于多个点的阶差上定义，在了解这个概念之前我们必须了解什么是差商的概念；\n",
    "\n",
    "从上边的拉格朗日插值法我们知道，对于多个点都是可以得到经过点的对应函数的，我们设为$f(x)$；\n",
    "\n",
    "设我们需要插值的点为： $(x_i,y_i) \\; \\; \\; \\; \\; \\; (i=0,1,2,\\cdots,n)$\n",
    "\n",
    "以两个点进行举例，设两个点：$(x_1,f(x_1))$ 和 $(x_2,f(x_2))$；\n",
    "\n",
    "需要构造一个阶差函数 $f_1(x)$ 来保证： \n",
    "\n",
    "$$\n",
    "f_1(x_1) = f(x_1) \\quad \\quad (x = x_1)\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "通过上边拉格朗日插值法，我们都知道如何去构建这样的插值多项式，即：\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "f_1(x) = f(x) + b_1(x-x_1)\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "我们求一下上边等式的 $b_1$ 的值，令 $f_1(x_2) = f(x_2)$：\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\begin{aligned}\n",
    "        f_1(x) \\; & = \\quad f(x) + b_1(x-x_1) \\\\ \\\\\n",
    "        & \\Rightarrow \\quad b_1 = \\frac{f(x_2)-f(x_1)}{x_2-x_1} \\\\ \\\\\n",
    "        & \\Rightarrow \\quad f_1(x) = f(x_1) + \\frac{f(x_2)-f(x_1)}{x_2-x_1}(x-x_1)\n",
    "    \\end{aligned}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "如果有三个点呢？\n",
    "\n",
    "设存在一个函数 $f_2(x)$ 满足三个点：$(x_1,f(x_1))$ $(x_2,f(x_2))$  $(x_3,f(x_3))$ :\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "f_2(x) \\; = \\quad f_1(x) + b_2(x-x_1)(x-x_2) \\\\\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "令 $f_2(x_3) = f(x_3)$:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\begin{aligned}\n",
    "        f_2(x) \\; & = \\quad f_1(x) + b_2(x-x_1)(x-x_2) \\\\ \\\\\n",
    "        & \\Rightarrow \\quad b_2 = \\frac{[\\frac{f(x_3)-f(x_2)}{x_3-x_2}]-[\\frac{f(x_2)-f(x_1)}{x_2-x_1}]}{x_3-x_1} \\\\\n",
    "        & \\Rightarrow \\quad f_2(x) = f(x_1) + \\frac{f(x_2)-f(x_1)}{x_2-x_1}(x-x_1) + \\frac{[\\frac{f(x_3)-f(x_2)}{x_3-x_2}]-[\\frac{f(x_2)-f(x_1)}{x_2-x_1}]}{x_3-x_1}(x-x_1)(x-x_2)\n",
    "    \\end{aligned}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "从上边得到对应的多项式插值公式,可以看到有一定的对应规律，我们记一阶差商为：$f[xi,xj](x \\neq j)$，记二阶差商为： $f[x_i,x_j,x_k](i \\neq j \\neq k)$  ....\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\begin{aligned}\n",
    "        f[x_i,x_j] & = \\frac{f(x_j)-f(x_i)}{x_j-x_i},\\quad (i \\neq j) \\\\\n",
    "        f[x_i,x_j,x_k] & = \\frac{f[i,j]-f[j,k]}{x_i-x_k},\\quad (i \\neq j \\neq k) \\\\\n",
    "        f[x_0,x_1,x_2,\\cdots,x_n] & = \\frac{f[x_1,x_2,\\cdots,x_k]-f[x_0,x_1,\\cdots,x_{n-1}]}{x_n-x_0}\n",
    "    \\end{aligned}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "说明：\n",
    "\n",
    "+ 在上边的公式中，$b_n$ 被重新记为 $f[x_1,x_2,\\dots,x_n]$，即为不同的差商；\n",
    "\n",
    "<br>\n",
    "\n",
    "综上，牛顿插值法的定义：\n",
    "\n",
    "知道了 $n$ 个点，可以构建牛顿插值多项式：\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "N_n(x) = f[x_0]w_0(x) + f[x_0,x_1]w_1(x) + \\cdots + f[x_0,x_1,\\cdots,x_n]w_n(x)\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "其中，$ w_0(x) = 1 $ &emsp; $w_n(x) = (x-x_0)(x-x_1)\\cdots(x-x_n)$\n",
    "\n",
    "在区间 $[a,b]$ 中的任意一点有：\n",
    "\n",
    "$$\n",
    "f(x) = N_n(x)+R_n(x)\n",
    "$$\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "牛顿插值法在 Pandas 中的应用：\n",
    "\n",
    "+ 类似于拉格朗日插值法，我们需要选定特定的列，即将数据类型从 Pandas.DataFrame 转为 Pandas.Series 类型；\n",
    "+ 选中空值周围的 $k$ 个数，选中的数据结构为：`(index, value)`\n",
    "+ 即选中的数据：$$ (x,y) \\\\ \\updownarrow \\\\ (x:代表行数{index},\\; y:代表选取的列在行{index}的值) $$ <br>\n",
    "+ 构建牛顿的插值法的函数；\n",
    "+ 将缺失值的 `index` 带入到多项式中求值；\n",
    "\n",
    "\n",
    "牛顿插值法的展 - 泰勒公式；\n",
    "\n",
    "\n",
    "参考链接：\n",
    "\n",
    "+ [Lagrange、Newton、分段插值法及Python实现](https://cloud.tencent.com/developer/article/1423591)\n",
    "+ [拉格朗日插值和牛顿插值（Python）](https://zhuanlan.zhihu.com/p/154460878)\n",
    "+ [牛顿插值的几何解释是怎么样的？ - 马同学的回答 - 知乎](https://www.zhihu.com/question/22320408/answer/141973314)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5a9a0a",
   "metadata": {},
   "source": [
    "#### 1.1.3 分段插值法 - 线性\n",
    "\n",
    "插值是在直线或曲线上的两点之间找到值的一种处理过程。 为了更好地理解插值的意义，这里我们这样说：即依据一系列点 (x,y)通过一定的算法找到一个合适的函数来逼近这些点，反映出这些点的走势规律。当拟合出插值函数后便可用这个插值函数计算其他 x 对应的的 y值，这就是插值的意义所在。\n",
    "\n",
    "分段插值法分为：线性插值法 (一阶)、二阶插值法(二次多项式);\n",
    "\n",
    "**线性插值法 (一阶)**\n",
    "\n",
    "对于线性分段插值法，在区间 $[a,b]$ 之间的所有数值按照从小到大的顺序进行排列，在两个数值点之间构成一个线性多项式，用整个区间的线性多项式来逼近构建的函数 $f(x)$\n",
    "\n",
    "**二阶插值法**\n",
    "\n",
    "选取插入点最近的三个点，来构建一个二次多项式；\n",
    "\n",
    "在 Scipy 中，提供了 `scipy.interpolate.interp1d` 来进行线性插值；\n",
    "\n",
    "我们使用上边的： `log_annual_inc` 的数据进行插值的计算；\n",
    "\n",
    "参考链接：\n",
    "\n",
    "+ [Python：插值interpolate模块](https://zhuanlan.zhihu.com/p/136700122)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5010c63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "打印出空值的行数\n",
      "3770   NaN\n",
      "6663   NaN\n",
      "7583   NaN\n",
      "7678   NaN\n",
      "Name: log_annual_inc, dtype: float64\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3770    10.543954\n",
       "6663    10.958594\n",
       "7583    10.989441\n",
       "7678    10.789844\n",
       "Name: log_annual_inc, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# 选取 - 列 log_annual_inc  使用深拷贝函数\n",
    "log_se = data_file[\"log_annual_inc\"].copy()\n",
    "\n",
    "# shuffle \n",
    "log_se = log_se.sample(frac=1.0).reset_index(drop=True)\n",
    "\n",
    "# 找出空值的相关\n",
    "print(\"打印出空值的行数\")\n",
    "print(log_se[log_se.isnull()])\n",
    "print(\"\\n\")\n",
    "\n",
    "# 构建函数 - 分段线性插值法\n",
    "def line_inter(se: pd.Series, null_valueIndex:list, k=3):\n",
    "    for sid in null_valueIndex:\n",
    "        # 选取相关的 index 数字列表\n",
    "        index_list = list(range(sid-k,k)) + list(range(k+1,k+sid))\n",
    "        y = se[index_list]\n",
    "        y = y[y.notnull()]\n",
    "        se[sid] = interp1d(list(y.index), list(y), kind=\"linear\")(sid)\n",
    "\n",
    "# 生成一个空值 Index 列表\n",
    "null_valueIndex = log_se[log_se.isnull()].index.tolist()\n",
    "\n",
    "# 放入上边的函数\n",
    "line_inter(log_se, null_valueIndex)\n",
    "# 打印\n",
    "log_se[null_valueIndex]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d564d7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**练习**\n",
    "$\\textsf{TODO - 1.2:}$\n",
    "\n",
    "请使用 `log_annual_inc` 列数据进行下边的练习；\n",
    "\n",
    "+ 1. 在上边我们完成了分段差值 - 线性的相关函数的构建，现在请查阅 interpolate. interp1d API:  [scipy.interpolate.interp1d](https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.interp1d.html)  完成构建一个 \"二次\" 插值多项式 - \"quadratic\" 的函数，请参考上边的代码撰写你的代码：\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00429fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "打印出空值的行数\n",
      "3471   NaN\n",
      "4193   NaN\n",
      "6933   NaN\n",
      "8887   NaN\n",
      "Name: log_annual_inc, dtype: float64\n",
      "\n",
      "\n",
      "二次插值多项式结果：\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3471    10.226107\n",
       "4193    11.249708\n",
       "6933     9.969369\n",
       "8887    10.506340\n",
       "Name: log_annual_inc, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 练习 1.2 完成区域\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98270046",
   "metadata": {},
   "source": [
    "#### 1.1.4 样条插值法\n",
    "\n",
    "在一组离散的数据基础上插补连续函数，类似于 拉格朗日插值多项式、牛顿插值多项式、分段差值法，都是在样本区间(离散数值区间)中找到一个函数将所有的样本点都在函数的曲线上； - 这也是插值的基本定义；\n",
    "\n",
    "**样条插值法**： 在两点之间确定一个函数，这个函数就是一个**样条**，所有的离散点之间都要生成一个样条，最后将所有的样条分段结合成一个函数；\n",
    "\n",
    "一般来说，样条插值的相关代表是：3次样条插值法 ；\n",
    "\n",
    "与常规的分段差值法的代表就是多项式的阶数；\n",
    "\n",
    "参考链接：\n",
    "\n",
    "+ [矩阵与数值计算（13）——分段低次插值与三次样条插值](https://zhuanlan.zhihu.com/p/331487422)\n",
    "+ [数值分析(6)：分段低次插值和三次样条插值](https://zhuanlan.zhihu.com/p/368911657)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa83e29d",
   "metadata": {},
   "source": [
    "### 1.2 异常值处理\n",
    "\n",
    "异常处理用来解决在数据集当中的异常值处理问题，异常值的判别方法有：$3\\sigma$原则，四分位数法等；\n",
    "\n",
    "**常见的异常值处理法**如下：\n",
    "\n",
    "|      异常值处理方法      |                           方法描述                           |\n",
    "| :----------------------: | :----------------------------------------------------------: |\n",
    "| 删除包含异常值的相关记录 |                将存在异常值的相关数据进行删除                |\n",
    "|    将异常值视为缺失值    | 使用缺失值的相关处理办法：拉格朗日插值法、样条插值法、牛顿插值法等进行处理 |\n",
    "|        平均值修正        |        使用异常值前后的值进行平均值，补充异常值的缺失        |\n",
    "|          不处理          | 在某些数据模型当中缺失值以及异常值不会造成相关的影响，因此不需要进行处理 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d9b3b1",
   "metadata": {},
   "source": [
    "## 2. 数据集成\n",
    "\n",
    "在数据挖掘分析当中，大多数数据集往往被分布在不同的数据源当中，数据集成就是将多个数据合并到一个数据结构当中；\n",
    "\n",
    "因为数据表现的形式是不同的，因此在集成数据的时候需要考虑到下边两个点：\n",
    "\n",
    "+ 1.实体的识别问题\n",
    "+ 2.属性的冗余问题\n",
    "\n",
    "<br>\n",
    "\n",
    "### 2.1 实体识别\n",
    "\n",
    "实体，在数据分析处理中，也可以被理解成为对象的概念，即数据分析的具体作用对象；\n",
    "\n",
    "常见的实体识别如下：\n",
    "\n",
    "1.同名异义\n",
    "\n",
    "不同数据源中的”同名“情况的处理，即在一些数据集中相同名称可能也会代表的是不同的含义；\n",
    "\n",
    "2.异名同义\n",
    "\n",
    "不同的数据源当中”异名“情况代表的是相同的含义；\n",
    "\n",
    "3.单位不统一\n",
    "\n",
    "在数据当中可能存在数据单位不一致的情况，针对单位不一致的情况需要统一相关的单位；\n",
    "\n",
    "<br>\n",
    "\n",
    "### 2.2 冗余属性识别\n",
    "\n",
    "数据集成往往会导致数据冗余，数据冗余的相关概念：\n",
    "\n",
    "+ 在数据集当中，同一个属性可能会出现多次，出现多次的原因可能是： 命名不一致导致重复、单位不一致导致重复\n",
    "\n",
    "在数据分析和预处理当中，需要对冗余的属性进行处理，从而提升建模的准确性；\n",
    "\n",
    "<br>\n",
    "\n",
    "### 2.3 数据变换\n",
    "\n",
    "数据变换指的是对数据进行规范化的处理，将数据转换成适当的相关形式；\n",
    "\n",
    "<br>\n",
    "\n",
    "### 2.4 简单函数变换\n",
    "\n",
    "函数的相关变化包括以下的几种：\n",
    "\n",
    "+ 平方\n",
    "+ 开方\n",
    "+ 取对数\n",
    "+ 差分运算\n",
    "\n",
    "在数据分析和预处理阶段中，可以通过相关的数据变化将本来不具备正态分布的相关数据变得符合正态分布，从而更好地去适应相关的数据模型需要；\n",
    "\n",
    "在时序分析当中，对数据进行简单的对数变换和查分运算可以将非平稳序列转换成伟平稳序列；\n",
    "\n",
    "<br>\n",
    "\n",
    "### 2.5 规范化(归一化)\n",
    "\n",
    "数据标准化（归一化）是建立数据模最重要的一项工作，在前边的相关工作当中，我们就已经知道了归一化可能对数据产生的影响；\n",
    "\n",
    "归一化解决的相关问题： 消除数据中量纲和取值范围差异的相关影响；\n",
    "\n",
    "方法：\n",
    "\n",
    "+ 对数据按比例进行缩放，进入到一个相对集中的区域中，以便进行综合分析；\n",
    "\n",
    "数据的规范化对基于相关距离的挖掘算法非常重要；\n",
    "\n",
    "常用的相关操作如下：\n",
    "\n",
    "+ 最小 - 最大规范化\n",
    "+ 零 - 均值规范化\n",
    "+ 小数定标规范化\n",
    "\n",
    "#### 2.5.1 最小-最大标准化\n",
    "\n",
    "最小-最大规范化也成为离差标准化，是对原始数据的线性变化，经过计算可以将所有的数值的取值区域都集中在： $[0,1]$  之间；\n",
    "\n",
    "转化的相关公式如下：\n",
    "\n",
    "$$\n",
    "x^* = \\frac{x-min}{max-min} \\\\\n",
    "\\\\\n",
    "\\\\\n",
    "max: 样本的最大值 \\;\\;\\; min: 样本的最小值\n",
    "$$\n",
    "\n",
    "问题：\n",
    "\n",
    "+ 如果数据集当中所有的数据都非常接近并且某个数出现机制的情况，那么最小-最大标准化的值都比较接近0；\n",
    "\n",
    "<br>\n",
    "\n",
    "作用:\n",
    "\n",
    "将某个特征的值映射到[0,1]之间，消除量纲对最终结果的影响，使不同的特征具有可比性，使得原本可能分布相差较大的特征对模型有相同权重的影响，提升模型的收敛速度，深度学习中数据归一化可以防止模型梯度爆炸；\n",
    "\n",
    "<br>\n",
    "\n",
    "#### 2.5.2 零-均值标准化\n",
    "\n",
    "零-均值标准化： 也被称为”标准差标准化“，经过”零-均值标准化“处理之后的相关数据均值为0，标准差为1；\n",
    "\n",
    "公式为：\n",
    "\n",
    "$$\n",
    "x^* = \\frac{x - \\overline x}{\\sigma}\\\\\n",
    "\\\\\n",
    "\\\\\n",
    "\\overline x: 数据集中的平均值 \\;\\;\\; \\sigma： 数据集中的标准差\n",
    "$$\n",
    "\n",
    "是使用最多的数据标准化方法；\n",
    "\n",
    "<br>\n",
    "\n",
    "#### 2.5.3 小数定标标准化\n",
    "\n",
    "通过移动相关移动属性值的小数位数，将属性值映射到：$[-1,1]$ 之间，移动的小数位数取决于属性值绝对值的最大值；\n",
    "\n",
    "$$\n",
    "x^* = \\frac{x}{10^k}\\\\\n",
    "\\\\\n",
    "\\\\\n",
    "k \\; 值取决于实际数据的大小\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "标准化的作用：\n",
    "\n",
    "+ 在回归的数据模型当中，归一化可以加快数学模型的收敛速度；\n",
    "+ 提升模型的精度；\n",
    "\n",
    "<br>\n",
    "\n",
    "参考链接：\n",
    "\n",
    "+ [归一化、标准化、零均值化作用及区别](https://zhuanlan.zhihu.com/p/183591302)\n",
    "+ [中心化（又叫零均值化）和标准化（又叫归一化）](https://blog.csdn.net/GoodShot/article/details/80373372)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c604a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9574.000000\n",
       "mean       10.931874\n",
       "std         0.614736\n",
       "min         7.547502\n",
       "25%        10.558414\n",
       "50%        10.927987\n",
       "75%        11.289832\n",
       "max        14.528354\n",
       "Name: log_annual_inc, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在这里我们使用 log_annual 来简单做一下常理的数值分析\n",
    "# 尝试打印一下相关的数据参数来反映相关的数据特征\n",
    "log_se = data_file[\"log_annual_inc\"].copy()\n",
    "log_se.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f128a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.1]       4\n",
       "(0.1, 0.2]      28\n",
       "(0.2, 0.3]     179\n",
       "(0.3, 0.4]    1220\n",
       "(0.4, 0.5]    4122\n",
       "(0.5, 0.6]    3236\n",
       "(0.6, 0.7]     681\n",
       "(0.7, 0.8]      79\n",
       "(0.8, 0.9]      20\n",
       "(0.9, 1.0]       4\n",
       "Name: log_annual_inc, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 尝试使用 最小-最大标准化\n",
    "# 打印一下相关数值的分布区间\n",
    "log_seMaxMin = (log_se - log_se.min()) / (log_se.max() - log_se.min())\n",
    "bin_log = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "pd.value_counts(pd.cut(log_seMaxMin, bin_log), sort=False)\n",
    "# 可以看出来 我们现在的数据大致可以满足正态分布的需要了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ecd13ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.9, -0.8]    201\n",
       "(-0.8, -0.7]    359\n",
       "(-0.7, -0.6]    252\n",
       "(-0.6, -0.5]    437\n",
       "(-0.5, -0.4]    286\n",
       "(-0.4, -0.3]    421\n",
       "(-0.3, -0.2]    302\n",
       "(-0.2, -0.1]    562\n",
       "(-0.1, 0.0]     381\n",
       "(0.0, 0.1]      294\n",
       "(0.1, 0.2]      576\n",
       "(0.2, 0.3]      375\n",
       "(0.3, 0.4]      369\n",
       "(0.4, 0.5]      456\n",
       "(0.5, 0.6]      335\n",
       "(0.6, 0.7]      313\n",
       "(0.7, 0.8]      282\n",
       "(0.8, 0.9]      220\n",
       "(0.9, 1.0]      269\n",
       "Name: log_annual_inc, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 尝试使用 零 - 均值标准化\n",
    "log_seMeanStd = (log_se - log_se.mean()) / log_se.std()\n",
    "bin_log = [-0.9,-0.8,-0.7,-0.6,-0.5,-0.4,-0.3,-0.2,-0.1,0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "pd.value_counts(pd.cut(log_seMeanStd, bin_log), sort=False)\n",
    "# 可以看到数值的分布如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e81e950b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.1]     573\n",
       "(0.1, 0.2]    9001\n",
       "(0.2, 0.3]       0\n",
       "(0.3, 0.4]       0\n",
       "(0.4, 0.5]       0\n",
       "(0.5, 0.6]       0\n",
       "(0.6, 0.7]       0\n",
       "(0.7, 0.8]       0\n",
       "(0.8, 0.9]       0\n",
       "(0.9, 1.0]       0\n",
       "Name: log_annual_inc, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 小数定标标准化\n",
    "log_decimalNor = log_se / 10 ** np.ceil(np.log10(log_se.abs().max()))\n",
    "bin_log = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "pd.value_counts(pd.cut(log_decimalNor, bin_log), sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44595302",
   "metadata": {},
   "source": [
    "### 2.6 连续属性的离散化\n",
    "\n",
    "连续属性的离散化： 将一组连续的值根据一定的规则分别放到其术语集合中，例如常见的算法：ID3算法、Apriori算法都是分类属性形式，将连续属性变换成分类属性；\n",
    "\n",
    "<br>\n",
    "\n",
    "**离散化数据的好处**：\n",
    "\n",
    "1. 离散特征的增加和减少都很容易，易于模型的快速迭代；\n",
    "\n",
    "2. 稀疏向量内积乘法运算速度快，计算结果方便存储，容易扩展；\n",
    "\n",
    "3. 离散化后的特征对异常数据有很强的鲁棒性：比如一个特征是年龄>30是1，否则0。如果特征没有离散化，一个异常数据“年龄300岁”会给模型造成很大的干扰；\n",
    "\n",
    "4. 逻辑回归属于广义线性模型，表达能力受限；单变量离散化为N个后，每个变量有单独的权重，相当于为模型引入了非线性，能够提升模型表达能力，加大拟合；\n",
    "\n",
    "5. 离散化后可以进行特征交叉，由M+N个变量变为M*N个变量，进一步引入非线性，提升表达能力；\n",
    "\n",
    "6. 特征离散化后，模型会更稳定，比如如果对用户年龄离散化，20-30作为一个区间，不会因为一个用户年龄长了一岁就变成一个完全不同的人。当然处于区间相邻处的样本会刚好相反，所以怎么划分区间是门学问；\n",
    "\n",
    "7. 特征离散化以后，起到了简化了逻辑回归模型的作用，降低了模型过拟合的风险。\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**过程**：\n",
    "\n",
    "+ 在数据的取值范围之内设定若干个离散的区间，将取值的范围划分为一些离散化的区间，使用不同的符号和代表落在每个自取件中的数据值；\n",
    "+ 因此离散化数据需要解决两个问题：\n",
    "    + 确定分类数 / 确定分类区间\n",
    "    + 将属性值映射到这些区间之中\n",
    "    \n",
    "<br>\n",
    "\n",
    "**方法**：\n",
    "\n",
    "1.等宽法\n",
    "\n",
    "将属性的值域分成具有相同宽度的区间，每一个区间的个数由数据本身的特征决定，或者分析者指定；\n",
    "\n",
    "\n",
    "2.等频法\n",
    "\n",
    "将相同数量的记录放在同一个区间；\n",
    "\n",
    "\n",
    "3.基于聚类的分析方法\n",
    "\n",
    "使用一维的聚类方法，使用 K-means 算法将所有连续的属性进行聚类，将聚类得到的蔟进行处理，并合并到一个蔟的连续属性值做同一标记。\n",
    "\n",
    "如果你不是很了解 K-means 算法，请单击下边的链接了解；\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "参考链接：\n",
    "\n",
    "+ [连续属性离散化](https://blog.csdn.net/Eaton18/article/details/52143616)\n",
    "+ [连续特征离散化的好处](https://blog.csdn.net/jbfsdzpp/article/details/47322949)\n",
    "+ [K-Means聚类算法原理](https://www.cnblogs.com/pinard/p/6164214.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78749e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2\n",
       "1       2\n",
       "2       1\n",
       "3       2\n",
       "4       2\n",
       "       ..\n",
       "9573    2\n",
       "9574    2\n",
       "9575    1\n",
       "9576    1\n",
       "9577    2\n",
       "Name: log_annual_inc, Length: 9578, dtype: category\n",
       "Categories (4, int64): [0 < 1 < 2 < 3]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 以上边的 log_annual 进行离散化的分析\n",
    "log_se = data_file[\"log_annual_inc\"]\n",
    "# 使用 pd.cut 函数来做等宽的离散化\n",
    "log_seWidthCut = pd.cut(log_se, bins=4, labels=range(4))\n",
    "# 打印一下相关的数据信息，可以看到\n",
    "log_seWidthCut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "981870e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0%       7.547502\n",
       "25%     10.558414\n",
       "50%     10.927987\n",
       "75%     11.289832\n",
       "100%    14.528354\n",
       "Name: log_annual_inc, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用等频法来进行相关的切割\n",
    "# 需要保证的是： 所有的分组区间的间距是等距的\n",
    "# 因此需要使用到等频率离散化的相关特征\n",
    "area_range = [1.0*i/4 for i in range(5)]\n",
    "log_se.describe(percentiles=area_range)[4:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0b32408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 检查当前环境的模块内容\n",
    "if platform.system()==\"windows\":\n",
    "    !pip install scikit-learn\n",
    "else:\n",
    "    !conda install --yes --prefix {sys.prefix} scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9f6b458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 接下来使用 Sklearn 来训练 K-means 的模型\n",
    "# 查询 KMeans API 链接： https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "from sklearn.cluster import KMeans\n",
    "kmodel = KMeans(n_clusters=4)\n",
    "# 使用数据集开始训练\n",
    "kmodel.fit(np.array(log_se[log_se.notnull()]).reshape((len(log_se[log_se.notnull()]),1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4255436a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>center_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.854571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.598990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.186815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.923407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   center_value\n",
       "3      9.854571\n",
       "0     10.598990\n",
       "1     11.186815\n",
       "2     11.923407"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 上边训练了 K-means 聚类模型，现在需要可视化数据模型\n",
    "# 首先获得四个中心点\n",
    "cluster_center = kmodel.cluster_centers_\n",
    "# 我们创建一个新的 DataFrame 来\n",
    "center_df = pd.DataFrame(cluster_center, columns=[\"center_value\"]).sort_values(by=\"center_value\")\n",
    "center_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8d1c9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   center_value\n",
      "3           NaN\n",
      "0     10.226780\n",
      "1     10.892903\n",
      "2     11.555111\n",
      "\n",
      "\n",
      "[0, 10.22678042705136, 10.892902614628186, 11.555110959709545, 14.52835448]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       2\n",
       "1       2\n",
       "2       1\n",
       "3       2\n",
       "4       2\n",
       "       ..\n",
       "9573    3\n",
       "9574    2\n",
       "9575    1\n",
       "9576    1\n",
       "9577    2\n",
       "Name: log_annual_inc, Length: 9578, dtype: category\n",
       "Categories (4, int64): [0 < 1 < 2 < 3]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 尝试打印一下相关的信息，上边的信息我们可以看到，我们选取了 4 个聚类中心点\n",
    "# 现在需要对相关的数据进行可视化\n",
    "# rolling 函数提供了相邻两个点的平均值\n",
    "# 我们需要构建一个离散区间，在下边的代码构建了一个新的变量： w\n",
    "w = center_df.rolling(window = 2).mean()\n",
    "print(w)\n",
    "w = w.dropna()\n",
    "w = [0] + list(w[\"center_value\"]) + [log_se.max()]\n",
    "print(\"\\n\")\n",
    "print(w)\n",
    "print('\\n')\n",
    "d_cluster = pd.cut(log_se, w, labels=range(4))\n",
    "d_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b2179e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 我们现在已经有了相关的数据，可以打印出相关的数据图像\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.title(\"K-Means Cluster Picture\", fontsize=15)\n",
    "plt.ylim(-0.5,4-0.5)\n",
    "for sid in range(0,4):\n",
    "    plt.plot(log_se[d_cluster==sid], [sid for i in d_cluster[d_cluster==sid]], 'x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5466855",
   "metadata": {},
   "source": [
    "## 3. 数据归约\n",
    "\n",
    "在大数据集中进行复杂的数据分析和挖掘都需要较长的时间，因此将数据归约或者最小化可以保持元数据的完整性；\n",
    "\n",
    "归约的意义在于：\n",
    "\n",
    "+ 降低无效、错误数据对于建模的影响，提高建模的准确性；\n",
    "+ 少量且具有代表性的数据可以大量减少数据挖掘的时间；\n",
    "+ 降低数据的存储成本\n",
    "\n",
    "<br>\n",
    "\n",
    "### 3.1 属性归约\n",
    "\n",
    "属性归约指的是将所有不必要的相关属性进行合并从而产生一个新属性维数，或者直接通过删除相关的属性（维度）来减少数据的复杂性，从而提升相关的数据挖掘效率，从而降低计算成本。\n",
    "\n",
    "属性归约的目标是： 尽量的寻找较小的属性子集并确保数据子集的概率分布尽可能接近原来数据集额概率分布；\n",
    "\n",
    "相关的常用属性归约方法：\n",
    "\n",
    "![属性归约常用方法](http://www.tjxzj.net/wp-content/uploads/2021/02/2021022007245775.jpg)\n",
    "\n",
    "在数据挖掘和机器学习领域中，最重要的数据预处理（归约）方法是：主成成分分析法(PCA)，其在建模的数据预处理当中有非常重要的应用背景；\n",
    "\n",
    "主成成分分析法 (PCA) 是一种用于连续数据属性的数据降维方法，重新构造了相关原始数据的一个正交变换，新的数据维度空间的基底去除了原始空间基底下数据的相关性，使用更少的变量数据去解释原始数据的大多数变量，即将相关性较高的变量转化彼此相互独立或不相关的变量。\n",
    "\n",
    "主成成分分析法使用少量的新变量就能够解释原始数据中大部分的变异，在实际的相关应用当中，做法是：\n",
    "\n",
    "+ 选出比原始属性变量少、能解释大部分数据中的变量的几个新变量；\n",
    "\n",
    "相关数学基础：\n",
    "\n",
    "+ 线性代数： 矩阵、单位矩阵、矩阵中心化、系数矩阵、矩阵换基底的相关概念；\n",
    "\n",
    "<br>\n",
    "\n",
    "**推导过程**：\n",
    "\n",
    "1.我们设定相关维度的矩阵如下，设相关的原始变量 $X_1,X_2,\\cdots,X_p$ 的相关 $n$ 次观测数据矩阵为式：\n",
    "<br>\n",
    "$$\n",
    "X =\n",
    "\\begin{pmatrix}\n",
    "x_{11} & x_{12} & \\cdots &x_{1p} \\\\\n",
    "x_{21} & x_{22} & \\cdots & x_{2p} \\\\\n",
    "\\cdots & \\cdots & \\cdots & \\cdots \\\\\n",
    "x_{n1} & x_{n2} & \\cdots & x_{np} \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "2.将数据矩阵按列进行中心标准化，利用即使用\"零-均值标准化方法\"，设矩阵为 $X \\in R_{(n \\times p)}$，\n",
    "\n",
    "矩阵标准化的相关计算过程如下，\n",
    "设该矩阵的均值为 $\\overline X$， 求 $\\overline X$:\n",
    "\n",
    "$$\n",
    "\\overline X = \\frac{\\sum\n",
    "\\begin{pmatrix}\n",
    "x_{11} & x_{12} & \\cdots &x_{1p} \\\\\n",
    "x_{21} & x_{22} & \\cdots & x_{2p} \\\\\n",
    "\\cdots & \\cdots & \\cdots & \\cdots \\\\\n",
    "x_{n1} & x_{n2} & \\cdots & x_{np} \\\\\n",
    "\\end{pmatrix}}\n",
    "{n \\times p}\n",
    "=\n",
    "\\begin{equation}\n",
    "\\frac{(x_{11} + x_{12} + \\cdots + x_{np})}{n \\times p}\n",
    "\\end{equation}\n",
    "=\n",
    "X_{mean} \\quad (在这里 X_{mean} 是一个数值)\n",
    "$$ \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "设该矩阵的标准差 $\\delta(X)$，计算过程如下：\n",
    "\n",
    "$$\n",
    "\\delta(X) = \n",
    "\\sqrt{\\frac{\\sum_{n=1,p=1}^{n,q}(x_{nq} - X_{mean})^2}{n \\times q}}\n",
    "\\quad (在这里标准差是一个数值，是整个矩阵的标准差，记为 \\delta)\n",
    "$$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "参考上边的归一化公式：\n",
    "\n",
    "$$\n",
    "x^* = \\frac{x - \\overline x}{\\sigma}\\\\\n",
    "\\\\\n",
    "\\\\\n",
    "\\overline x: 数据集中的平均值 \\;\\;\\; \\delta： 数据集中的标准差\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "则中心标准化的公式是：\n",
    "\n",
    "$$\n",
    "X_{scale} = \n",
    "\\begin{pmatrix}\n",
    "\\frac{x_{11}-X_{mean}}{X_{\\delta}} & \\frac{x_{12}-X_{mean}}{X_{\\delta}} & \\cdots & \\frac{x_{1p}-X_{mean}}{X_{\\delta}} \\\\\n",
    "\\frac{x_{21}-X_{mean}}{X_{\\delta}} & \\frac{x_{22}-X_{mean}}{X_{\\delta}} & \\cdots & \\frac{x_{2p}-X_{mean}}{X_{\\delta}} \\\\\n",
    "\\cdots & \\cdots & \\cdots & \\cdots \\\\\n",
    "\\frac{x_{n1}-X_{mean}}{X_{\\delta}} & \\frac{x_{n2}-X_{mean}}{X_{\\delta}} & \\cdots & \\frac{x_{np}-X_{mean}}{X_{\\delta}} \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "3.求相关系数矩阵 $R$，这里的相关系数矩阵是由统计学家 Pearson 提出的用于反映两个统计变量之间线性相关的系数，参考之前的相关定义形式：\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\frac{\\sum_{i=1}^n{(X_i-\\overline{X})(Y_i-\\overline{Y})}}{\\sqrt{\\sum_{i=1}^n(X_i-\\overline{X})^2\\sum_{i=1}^n(Y_i-\\overline{Y})^2}}\n",
    "\\end{equation}\n",
    "$$\n",
    "<br>\n",
    "\n",
    "设 $R=(r_{ij})_{p \\times p}$，在这里我们需要明晰 $i,j$ 的取值区间为：$i \\in (1,p)$ $j \\in (1,p)$，对于相关系数矩阵的相关特性：1) $r_{ij} = r_{ji}$，即相关系数矩阵是一个对称矩阵； 2）$r_{ii} = 1$\n",
    "<br>\n",
    "计算公式如下：\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "r_{ij} = \n",
    "\\frac{\n",
    "\\sum_{k=1}^n{(x_{ki} - \\overline x_i)(x_{kj} - \\overline x_j)}\n",
    "}\n",
    "{\n",
    "\\sqrt{\\sum_{k=1}^n{(x_{ki} - \\overline x_i)^2}\\sum_{k=1}^n{(x_{kj} - \\overline x_j)^2}}\n",
    "}\n",
    "\\end{equation}\n",
    "$$\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "4.现在需要求特征方程，设满足上述相关系数矩阵 $R$ 的单位矩阵为 $E$，需要求的是满足 $|R-\\lambda E|=0$ 中的特征根（特征值） $\\lambda_i$\n",
    "\n",
    "<br>\n",
    "\n",
    "5.确定主成分个数 m 来保存最大的信息值，那么求保留的信息值大小：\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\frac{\n",
    "\\sum_{i=1}^m{\\lambda_i}\n",
    "}{\n",
    "\\sum_{i=1}^p{\\lambda_i}\n",
    "} \\geq \\alpha\n",
    "\\end{equation}\n",
    "$$\n",
    "<br>\n",
    "\n",
    "6.求对应的特征向量：$\\beta_1, \\beta_2, \\beta_3, \\cdots, \\beta_m$\n",
    "\n",
    "设我们已经计算出了 $\\lambda_1$ 求对应的特征向量 $x_{i1} \\in \\beta_1$ 且 $i \\in (1,p)$：\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "(\\lambda_1 E - X )\\beta_1 = (\\lambda_1 E - X)\n",
    "\\begin{pmatrix}\n",
    "\\beta_{11} \\\\\n",
    "\\beta_{12} \\\\\n",
    "\\dots \\\\\n",
    "\\beta_{p1}\\\\\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n",
    "= 0\n",
    "$$\n",
    "\n",
    "<br>\n",
    "7.设 $X_i = \\begin{pmatrix}\n",
    "x_{i1} \\\\\n",
    "x_{i2} \\\\\n",
    "\\dots \\\\\n",
    "x_{i1}\\\\\n",
    "\\end{pmatrix} \\in X$ 且 $i \\in (1,p)$，则计算主成分的相关公式为：\n",
    "\n",
    "<br>\n",
    "$$\n",
    "\\begin{equation}\n",
    "Z_i = \\beta_{1i}X_1 + \\beta_{2i}X_2 + \\dots + \\beta_{pi}X_p\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "参考链接：\n",
    "\n",
    "+ [详细推导PCA算法](https://zhuanlan.zhihu.com/p/55297233)\n",
    "+ [机器学习中的数学(2)——矩阵中心化、标准化的意义和作用](https://blog.csdn.net/liuweiyuxiang/article/details/77559781)\n",
    "+ [协方差矩阵和相关系数矩阵](https://zhuanlan.zhihu.com/p/363213507)\n",
    "+ [协方差矩阵和矩阵相关系数的理解](https://blog.csdn.net/qq_29750461/article/details/81625470)\n",
    "+ [矩阵特征值和特征向量详细计算过程](https://blog.csdn.net/Junerror/article/details/80222540)\n",
    "+ [线性代数(二十九) ：特征值与特征向量的计算](https://blog.csdn.net/mathmetics/article/details/20128203)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ecc8b527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/doheras/opt/anaconda3/envs/auto_Demo/lib/python3.7/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>fico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.002100</td>\n",
       "      <td>3.68</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.308953</td>\n",
       "      <td>14.12</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.491274</td>\n",
       "      <td>22.13</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.050890</td>\n",
       "      <td>13.79</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.987197</td>\n",
       "      <td>6.30</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.422281</td>\n",
       "      <td>20.11</td>\n",
       "      <td>717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.034890</td>\n",
       "      <td>26.74</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.350407</td>\n",
       "      <td>5.73</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.239960</td>\n",
       "      <td>0.00</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11.700060</td>\n",
       "      <td>13.99</td>\n",
       "      <td>677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   log_annual_inc    dti  fico\n",
       "0       11.002100   3.68   667\n",
       "1       10.308953  14.12   662\n",
       "2       10.491274  22.13   667\n",
       "3       11.050890  13.79   737\n",
       "4        8.987197   6.30   707\n",
       "5       10.422281  20.11   717\n",
       "6       11.034890  26.74   737\n",
       "7       11.350407   5.73   777\n",
       "8       10.239960   0.00   692\n",
       "9       11.700060  13.99   677"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 现在我们尝试一下使用 ski-learn 的PCA主成分分析法来进行相关的数据降维\n",
    "# 我们先尝试选取一下相关的数据\n",
    "from sklearn.decomposition import PCA\n",
    "# 打乱相关的数据集\n",
    "pca_rawData = data_file[[\"log_annual_inc\",\"dti\",\"fico\"]].copy().sample(frac=1.0, random_state = 23).reset_index(drop=True)\n",
    "\n",
    "# 数据集中可能存在相关的空值问题，我们使用拉格朗日插值法进行相关的缺失值补充\n",
    "def pd_lagrange(se: pd.Series, null_valueIndex: list, k=3):\n",
    "    # se: Pandas.Series 数据结构\n",
    "    # null_valueIndex: List 存放空值行数\n",
    "    # k: 选取前后行的数字\n",
    "    \n",
    "    # 遍历所有的空值行\n",
    "    for index in null_valueIndex:\n",
    "        # 选取上下K的数据\n",
    "        y_se = se[list(range(index-k,index)) + list(range(index+1, index+k+1))]\n",
    "        # 将空值的行去掉\n",
    "        y_se = y_se[y_se.notnull()]\n",
    "        # 将上边所有的值输入到拉格朗日多项式中，并且生成一个新的多项式；\n",
    "        # 并使用 pd.loc 函数来重新赋值空值行\n",
    "        se.loc[index] = scipy.interpolate.lagrange(list(y_se.index), list(y_se))(index)\n",
    "\n",
    "for name in pca_rawData.columns:\n",
    "    null_valueIndex = pca_rawData[pca_rawData[name].isnull()].index.tolist()\n",
    "    pd_lagrange(pca_rawData[name], null_valueIndex)\n",
    "        \n",
    "# 打印一下我们可能用到的相关数据类型\n",
    "pca_rawData.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "581151fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 请查阅相关的 PCA API：https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
    "pca_model = PCA(n_components=2)\n",
    "pca_model.fit(pca_rawData)\n",
    "pca_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c449e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00802848, -0.04507881,  0.99895117],\n",
       "       [ 0.91850092, -0.39461571, -0.0251894 ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 我们可以尝试打印相关的特征：\n",
    "# 通过上边的公式我们可以知道通过PCA算法可以知道了相关属性的的特征向量，每一个特征向量代表一个被压缩的维度\n",
    "pca_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "513af77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94096218, 0.0302553 ])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 也可以求出对应成分的贡献百分比\n",
    "pca_model.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f258148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.33981270e+01  4.60374662e+00]\n",
      " [-4.88690706e+01 -2.67507426e-02]\n",
      " [-4.42339323e+01 -3.14610706e+00]\n",
      " ...\n",
      " [-1.36519742e+01  1.12413387e+00]\n",
      " [ 1.10463125e+01 -1.49504348e+00]\n",
      " [ 8.04302507e+01 -8.33084256e+00]]\n",
      "\n",
      "\n",
      "[[ 14.90761698  12.74630413 667.37773902]\n",
      " [ 10.61057752  14.82019478 662.02917296]\n",
      " [  7.78265902  15.84219526 666.73802454]\n",
      " ...\n",
      " [ 11.95040601  12.77849274 697.18034257]\n",
      " [  9.74297903  12.69869184 721.91870058]\n",
      " [  4.0213392   12.26846003 791.40205661]]\n"
     ]
    }
   ],
   "source": [
    "# 知道了低维度的相关数据也可以通过压缩的维度信息来还原信息\n",
    "pca_lowDimenData = pca_model.transform(pca_rawData)\n",
    "print(pca_lowDimenData)\n",
    "original_data = pca_model.inverse_transform(pca_lowDimenData)\n",
    "print(\"\\n\")\n",
    "print(original_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc3ca80",
   "metadata": {},
   "source": [
    "### 3.2 数值归约\n",
    "\n",
    "在常见的大数据当中，存在数值区域过于广泛的情况，因此需要用到相关的数据归约的方法来选择替代的、较小的数据量，从而减少对应的数据量；\n",
    "\n",
    "数值规约的两种形式： 参数方法 和 无参方法；\n",
    "\n",
    "+ 参数方法：\n",
    "    + 使用相关的数学模型来评估数据，只需要知道数据模型的相关参数： 线性回归模型、多元回归模型；\n",
    "+ 无参方法：\n",
    "    + 直方图、聚类、抽样来进行数值规约；\n",
    "    \n",
    "<br>\n",
    "\n",
    "#### 3.2.1 无参数据规约\n",
    "\n",
    "**1.直方图**\n",
    "\n",
    "使用直方图划分区间来近似数据的分布，是一种流行的数据规约方式；\n",
    "\n",
    "<br>\n",
    "\n",
    "**2.聚类**\n",
    "\n",
    "聚类技术奖数据元组(数据表中的一行)视为对象，将相关、相似的对象划分在一起；\n",
    "<br>\n",
    "\n",
    "**3.抽样**\n",
    "\n",
    "抽样指的是将原来数据集中抽出相关随机样本（子集）表示原来的数据集；\n",
    "\n",
    "常用的数据抽样方法：\n",
    "\n",
    "1）$s$ 个样本的无放回随机抽样\n",
    "\n",
    "\n",
    "2）$s$ 个样本的放回随机抽样\n",
    "\n",
    "\n",
    "3）聚类抽样\n",
    "\n",
    "+ 聚类抽样将原始的数据集中的元组放进不相交的”蔟“，就可以得到对应个数的简单随机抽样；\n",
    "\n",
    "\n",
    "4）分层抽样\n",
    "\n",
    "+ 将原始的数据集分成不想交的部分，每一个不想交的部分称作：”层“。对每层的随机抽样就可以得到对应的元项数据及的分层样本；\n",
    "\n",
    "<br>\n",
    "\n",
    "#### 3.2.2 有参数据规约\n",
    "\n",
    "线性回归相关概念将会在后边的内容讲到，感兴趣的了解可以单击下边的链接了解相关知识：\n",
    "\n",
    "参考链接：\n",
    "\n",
    "+ [用人话讲明白线性回归LinearRegression](https://zhuanlan.zhihu.com/p/72513104)\n",
    "+ [线性回归 – linear regression](https://easyai.tech/ai-definition/linear-regression/)\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "补充链接\n",
    "\n",
    "+ [Python数据挖掘008-数据规约](https://www.jianshu.com/p/5ddae5e12ecc)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auto_demo",
   "language": "python",
   "name": "auto_demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
